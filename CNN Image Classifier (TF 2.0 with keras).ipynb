{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/a9/9828dfaf93f40e190ebfb292141df6b7ea1a2d57b46263e757f52be8589f/opencv_python-4.1.2.30-cp36-cp36m-manylinux1_x86_64.whl (28.3MB)\n",
      "\u001b[K     |████████████████████████████████| 28.3MB 19.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages (from opencv-python) (1.17.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.1.2.30\n"
     ]
    }
   ],
   "source": [
    "!pip install --user --upgrade opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import boto3\n",
    "from collections import Counter\n",
    "from random import shuffle, randint, seed\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 4.1.2\n",
      "Tensorflow version: 2.0.0\n",
      "Pillow version: 5.2.0\n"
     ]
    }
   ],
   "source": [
    "print(f'OpenCV version: {cv2.__version__}')\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Pillow version: {PIL.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATE = datetime.date(2019, 11, 21).strftime('%d-%b-%Y')\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "PATH = 'uploads/'\n",
    "MODEL_PATH = f'models/{DATE}/'\n",
    "MODEL_NAME = 'ImageClassifier-keras-5-Conv-Layer-{}.model'.format(int(time.time()))\n",
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read in Labels Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('labels.txt', 'r') as file:\n",
    "    LABELS = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Bucket Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acl',\n",
       " 'Cors',\n",
       " 'Lifecycle',\n",
       " 'LifecycleConfiguration',\n",
       " 'Logging',\n",
       " 'Notification',\n",
       " 'Object',\n",
       " 'Policy',\n",
       " 'RequestPayment',\n",
       " 'Tagging',\n",
       " 'Versioning',\n",
       " 'Website']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket('pornilarity-bucket170933-production')\n",
    "bucket.get_available_subresources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all images from S3 Bucket into local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in bucket.objects.all():\n",
    "    name = key.key.split('/')[1]\n",
    "    # print(key.key)\n",
    "    bucket.download_file(key.key, f'uploads/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    test_images = []\n",
    "    for img in tqdm(os.listdir(PATH)):\n",
    "        img_name = str(img) \n",
    "        full_path = os.path.join(PATH, img)  # full path of the image\n",
    "        # print(full_path)\n",
    "        # feature extraction\n",
    "        try:\n",
    "            img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = tf.cast(img, tf.float32)  # change data type of image to float32\n",
    "            test_images.append(img)\n",
    "        except Exception as e:\n",
    "            print(full_path)\n",
    "            print(str(e))\n",
    "            continue\n",
    "            \n",
    "    return np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 33/45 [00:00<00:00, 39.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads/.ipynb_checkpoints\n",
      "OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:01<00:00, 38.86it/s]\n"
     ]
    }
   ],
   "source": [
    "test_images = process_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for img in test_images:\\n    print(img.shape)'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = np.array([i for i in test_images]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "\"\"\"for img in test_images:\n",
    "    print(img.shape)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 95)                24415     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 95)                0         \n",
      "=================================================================\n",
      "Total params: 1,472,255\n",
      "Trainable params: 1,471,295\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL = tf.keras.models.load_model(f'{MODEL_PATH}')\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_INDEX = dict(zip(list(range(len(LABELS))), LABELS))\n",
    "IMAGE_IDs = iter(range(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(test_images, IMAGE_IDs):\n",
    "    results = {cls: [] for cls in LABELS}\n",
    "    predicted_labels = []\n",
    "    for img in test_images:\n",
    "        img = img / 255.0\n",
    "        img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        pred = MODEL.predict(img).flatten()\n",
    "        index = np.argmax(pred)\n",
    "        label = LABELS[index]\n",
    "        results = {LABELS[i]: results.get(LABELS[i]) + [pred[i]] for i in range(len(LABELS))}\n",
    "        print(f\"Image ID: {next(IMAGE_IDs)}\\t | Prediction: {label}\")\n",
    "        predicted_labels.append(label)\n",
    " \n",
    "    return np.array(predicted_labels), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID: 0\t | Prediction: Evelina Darling\n",
      "Image ID: 1\t | Prediction: Catarina Petrov\n",
      "Image ID: 2\t | Prediction: Samantha Ryan\n",
      "Image ID: 3\t | Prediction: Jessica Bangkok\n",
      "Image ID: 4\t | Prediction: Marcelin Abadir\n",
      "Image ID: 5\t | Prediction: Nicole Aniston\n",
      "Image ID: 6\t | Prediction: Audrey Bitoni\n",
      "Image ID: 7\t | Prediction: Amirah Adara\n",
      "Image ID: 8\t | Prediction: Marcelin Abadir\n",
      "Image ID: 9\t | Prediction: Emily Willis\n",
      "Image ID: 10\t | Prediction: Dana DeArmond\n",
      "Image ID: 11\t | Prediction: Lana Rhoades\n",
      "Image ID: 12\t | Prediction: Samantha Ryan\n",
      "Image ID: 13\t | Prediction: Xev Bellringer\n",
      "Image ID: 14\t | Prediction: Sarah Banks\n",
      "Image ID: 15\t | Prediction: Cherie De Ville\n",
      "Image ID: 16\t | Prediction: Bridgette B\n",
      "Image ID: 17\t | Prediction: Karlie Montana\n",
      "Image ID: 18\t | Prediction: Sunny Leone\n",
      "Image ID: 19\t | Prediction: Madison Ivy\n",
      "Image ID: 20\t | Prediction: Allie Haze\n",
      "Image ID: 21\t | Prediction: Veronica Rodriguez\n",
      "Image ID: 22\t | Prediction: Brenda James\n",
      "Image ID: 23\t | Prediction: Aiden Starr\n",
      "Image ID: 24\t | Prediction: Julia Ann\n",
      "Image ID: 25\t | Prediction: Gianna Dior\n",
      "Image ID: 26\t | Prediction: Valentina Nappi\n",
      "Image ID: 27\t | Prediction: Blake Bartelli\n",
      "Image ID: 28\t | Prediction: Misty Stone\n",
      "Image ID: 29\t | Prediction: Sunny Leone\n",
      "Image ID: 30\t | Prediction: Isabelle Deltore\n",
      "Image ID: 31\t | Prediction: Kristen Scott\n",
      "Image ID: 32\t | Prediction: Zoey Holloway\n",
      "Image ID: 33\t | Prediction: Riley Steele\n",
      "Image ID: 34\t | Prediction: Tiffany Tatum\n",
      "Image ID: 35\t | Prediction: Krystal Boyd\n",
      "Image ID: 36\t | Prediction: Tanya Tate\n",
      "Image ID: 37\t | Prediction: Madison Ivy\n",
      "Image ID: 38\t | Prediction: Audrey Bitoni\n",
      "Image ID: 39\t | Prediction: Romi Rain\n",
      "Image ID: 40\t | Prediction: Andriana Chechik\n",
      "Image ID: 41\t | Prediction: Mia Khalifa\n",
      "Image ID: 42\t | Prediction: Peta Jensen\n",
      "Image ID: 43\t | Prediction: Stella Cox\n"
     ]
    }
   ],
   "source": [
    "PREDICTED_LABELS, RESULTS = get_predictions(test_images, IMAGE_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top 5 results for Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Re-structures the results dictionary so that each class_label points to another dictionary {k, v}\n",
    "where k = the Image_Id number and v = the confidence value\n",
    "\"\"\"\n",
    "IMAGE_IDs = list(range(len(test_images)))\n",
    "def gen_results(results):\n",
    "    my_dict = {}\n",
    "    for cls in LABELS:\n",
    "        probs = iter(results[cls])\n",
    "        my_dict.update({cls: {}})\n",
    "        for k in IMAGE_IDs:\n",
    "            my_dict[cls][int(k)] = next(probs)\n",
    "\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top5(results, ID=1):\n",
    "    results = gen_results(results)\n",
    "    probs = np.array([(results[k][ID]) for k in results])\n",
    "    # print(f'Reverse: {(-probs).argsort()} - {sorted(probs, reverse=True)}')\n",
    "    indices = (-probs).argsort()[:5] # sorts probabilities (largest - smallest) + returns their corresponding array indices\n",
    "    top_5 = [CLASS_INDEX.get(i) for i in indices]\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Audrey Bitoni',\n",
       " 'Cameron Canela',\n",
       " 'Lana Rhoades',\n",
       " 'Gianna Dior',\n",
       " 'Jelena Jensen']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image_ID = 6\n",
    "TOP_5 = get_top5(RESULTS, Image_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Top5.txt\", TOP_5, fmt=\"%s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
