{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import os\n",
    "import generate_labels_text_file\n",
    "from collections import Counter\n",
    "from random import shuffle, randint, seed\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "OpenCV version: 4.1.1",
      "\n",
      "Tensorflow version: 2.0.0",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(f'OpenCV version: {cv2.__version__}')\n",
    "print(f'Tensorflow version: {tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Default GPU Device: /device:GPU:0",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Check what folder to use for training and testing images\n",
    "# CHISOM_TRAIN_DIR = 'C:/Users/chiso/MEGA/data/train'\n",
    "#CHISOM_TEST_DIR = 'C:/Users/chiso/MEGA/data/test'\n",
    "CHISOM_ALIGNED_TRAIN_DIR = 'C:/Users/chiso/MEGA/data/aligned_train'\n",
    "CHISOM_ALIGNED_TEST_DIR = 'C:/Users/chiso/MEGA/data/aligned_test'\n",
    "\n",
    "# YISI_TRAIN_DIR = 'E:/MegaSync/data/train'\n",
    "#YISI_TEST_DIR = 'E:/MegaSync/data/test'\n",
    "YISI_ALIGNED_TRAIN_DIR = 'E:/MegaSync/data/aligned_train'\n",
    "YISI_ALIGNED_TEST_DIR = 'E:/MegaSync/data/aligned_test'\n",
    "\n",
    "\n",
    "def get_directories():\n",
    "    if os.path.exists(CHISOM_ALIGNED_TRAIN_DIR) and os.path.exists(CHISOM_ALIGNED_TEST_DIR):\n",
    "        return CHISOM_ALIGNED_TRAIN_DIR, CHISOM_ALIGNED_TEST_DIR\n",
    "    else:\n",
    "        return YISI_ALIGNED_TRAIN_DIR, YISI_ALIGNED_TEST_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(95, 100)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 67
    }
   ],
   "source": [
    "DATE = datetime.datetime.now().strftime('%d-%b-%Y')\n",
    "ALIGNED_TRAIN_DIR, ALIGNED_TEST_DIR = get_directories()\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "MODEL_PATH = f'models/{DATE}/'\n",
    "MODEL_NAME = 'ImageClassifier-keras-5-Conv-Layer-{}.model'.format(int(time.time()))\n",
    "TENSORBOARD = TensorBoard(log_dir=f'logs\\\\{MODEL_NAME}') \n",
    "NUM_CLASSES = len(next(os.walk(ALIGNED_TRAIN_DIR))[1])\n",
    "NUM_CLASSES, IMG_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "('C:/Users/chiso/MEGA/data/aligned_train',\n 'C:/Users/chiso/MEGA/data/aligned_test')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 68
    }
   ],
   "source": [
    "ALIGNED_TRAIN_DIR, ALIGNED_TEST_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walkthrough of Subfolders in Train Directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Roots = C:/Users/chiso/MEGA/data/aligned_train",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Only the root\n",
    "ROOTS = next(os.walk(ALIGNED_TRAIN_DIR))[0]\n",
    "print(f\"Roots = {ROOTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['Abella Danger',\n 'Aiden Starr',\n 'Aidra Fox',\n 'Aletta Ocean',\n 'Alina Li',\n 'Alina Lopez',\n 'Allie Haze',\n 'Amirah Adara',\n 'Andriana Chechik',\n 'Angel Princess',\n 'Ariella Ferrera',\n 'Audrey Bitoni',\n 'Ava Addams',\n 'Bella Milano',\n 'Blake Bartelli',\n 'Brandi Love',\n 'Bree Daniels',\n 'Brenda James',\n 'Bridgette B',\n 'Cameron Canela',\n 'Cassidy Klein',\n 'Catarina Petrov',\n 'Chastity Lynn',\n 'Cherie De Ville',\n 'Christy Mack',\n 'Dana DeArmond',\n 'Dana Weyron',\n 'Dani Daniels',\n 'Elexis Monroe',\n 'Emily Willis',\n 'Eva Notty',\n 'Evelina Darling',\n 'Gianna Dior',\n 'Isabelle Deltore',\n 'Jelena Jensen',\n 'Jenna Sativa',\n 'Jessa Rhodes',\n 'Jessica Bangkok',\n 'Julia Ann',\n 'Karlie Montana',\n 'Katie A Delicia',\n 'Kayla Kayden',\n 'Kimmy Granger',\n 'Krissie Dee',\n 'Kristen Scott',\n 'Krystal Boyd',\n 'Lana Rhoades',\n 'Lena Reif',\n 'Lexi Diamond',\n 'Leyla Fiore',\n 'Linda Sweet',\n 'Lisa Ann',\n 'Little Caprice',\n 'Lizzie Ryan',\n 'Lola Myluv',\n 'Luna Star',\n 'Madison Ivy',\n 'Marcelin Abadir',\n 'Mellanie Monroe',\n 'Mia Khalifa',\n 'Mia Malkova',\n 'Mila Azul',\n 'Miranda Deen',\n 'Misty Stone',\n 'Nancy A',\n 'Nelly Kent',\n 'Nicole Aniston',\n 'Nicolette Shea',\n 'Penelope Y Sophia',\n 'Peta Jensen',\n 'Quinn Wilde',\n 'Rachel Starr',\n 'Riley Reid',\n 'Riley Steele',\n 'Romi Rain',\n 'Samantha Ryan',\n 'Sammie Rhodes',\n 'Sarah Banks',\n 'Sarah Vandella',\n 'Shera Bechard',\n 'Sheri Vi',\n 'Shyla Jennings',\n 'Sinn Sage',\n 'Sophia Laure',\n 'Stella Cox',\n 'Sunny Leone',\n 'Sydney Cole',\n 'Tanya Tate',\n 'Tiffany Tatum',\n 'Valentina Nappi',\n 'Veronica Avluv',\n 'Veronica Rodriguez',\n 'Wu Muxi',\n 'Xev Bellringer',\n 'Zoey Holloway']"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 70
    }
   ],
   "source": [
    "# Only the directories\n",
    "DIRS = next(os.walk(ALIGNED_TRAIN_DIR))[1]\n",
    "DIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"for root, dirs, files in os.walk(ALIGNED_TRAIN_DIR):\\n    for name in files:\\n        print(name.split('.')[0]) # filters the file name by file extension and the copy_number\\n        \\n\""
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 71
    }
   ],
   "source": [
    "# Only the files\n",
    "\"\"\"for root, dirs, files in os.walk(ALIGNED_TRAIN_DIR):\n",
    "    for name in files:\n",
    "        print(name.split('.')[0]) # filters the file name by file extension and the copy_number\n",
    "        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "LABELS = next(os.walk(ALIGNED_TRAIN_DIR))[1] # all the class labels (pornstar names) to be used\n",
    "LABELS = np.reshape(LABELS, (-1, 1)) # reshapes array from 1D to 2D array\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_labels = np.array(mlb.fit_transform(LABELS))\n",
    "# dict(zip(LABELS.flatten(), encoded_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# img.split('.')[0].split('(')[0]  # filters the file name by file extension and the copy_number\n",
    "\"\"\"\n",
    "Labelled training data\n",
    "\"\"\"\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    # iterate over each image-class (subfolder) in training directory\n",
    "    for folder in tqdm(os.listdir(ALIGNED_TRAIN_DIR)):\n",
    "        full_path = f'{ALIGNED_TRAIN_DIR}/{folder}'\n",
    "        # iterate over each image in each subfolder\n",
    "        for img in os.listdir(full_path):\n",
    "            ##### !python align_images.py raw_images/ aligned_images/ --output_size=1048\n",
    "            img_name = str(folder)  # the sub-folder is used as the image name for each image\n",
    "            img_name = img_name.strip() # removes any leading and trailing whitespaces from the img name\n",
    "            label = mlb.transform([[img_name]]) # encodes the label of the image using MultiLabelBinarizer\n",
    "            label = label.flatten()  # converts encoded label from 2D to 1D array\n",
    "            # print(f'Image: {img} - Encoding:{label}')\n",
    "            path = os.path.join(full_path, img)  # full path of the image\n",
    "            # feature extraction\n",
    "            img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "            img = tf.cast(img, tf.float32) # change data type of image to float32\n",
    "            training_data.append([np.array(img), np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unlabelled test data\n",
    "\"\"\"\n",
    "def process_test_data():\n",
    "    img_ids = list(range(len(os.listdir(ALIGNED_TEST_DIR)))) # generates list of ID numbers\n",
    "    shuffle(img_ids) # randomly assorted\n",
    "    img_ids = iter(img_ids) \n",
    "    testing_data = [] \n",
    "    for img in tqdm(os.listdir(ALIGNED_TEST_DIR)):\n",
    "        path = os.path.join(ALIGNED_TEST_DIR, img)\n",
    "        img_num = next(img_ids)\n",
    "        print(f\"ID: {img_num} \\t- Image: {img}\")\n",
    "        # feature extraction\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE))\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Generate Training and Testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|          | 0/95 [00:00<?, ?it/s]",
      "\r  1%|          | 1/95 [00:03<04:53,  3.12s/it]",
      "\r  2%|▏         | 2/95 [00:04<04:08,  2.68s/it]",
      "\r  3%|▎         | 3/95 [00:07<04:05,  2.67s/it]",
      "\r  4%|▍         | 4/95 [00:09<03:46,  2.49s/it]",
      "\r  5%|▌         | 5/95 [00:12<03:55,  2.62s/it]",
      "\r  6%|▋         | 6/95 [00:15<03:54,  2.64s/it]",
      "\r  7%|▋         | 7/95 [00:17<03:47,  2.58s/it]",
      "\r  8%|▊         | 8/95 [00:20<03:48,  2.62s/it]",
      "\r  9%|▉         | 9/95 [00:22<03:36,  2.51s/it]",
      "\r 11%|█         | 10/95 [00:24<03:12,  2.26s/it]",
      "\r 12%|█▏        | 11/95 [00:26<03:20,  2.38s/it]",
      "\r 13%|█▎        | 12/95 [00:29<03:32,  2.56s/it]",
      "\r 14%|█▎        | 13/95 [00:33<04:02,  2.96s/it]",
      "\r 15%|█▍        | 14/95 [00:36<03:52,  2.88s/it]",
      "\r 16%|█▌        | 15/95 [00:38<03:37,  2.72s/it]",
      "\r 17%|█▋        | 16/95 [00:42<03:51,  2.93s/it]",
      "\r 18%|█▊        | 17/95 [00:44<03:34,  2.75s/it]",
      "\r 19%|█▉        | 18/95 [00:45<03:01,  2.36s/it]",
      "\r 20%|██        | 19/95 [00:48<03:01,  2.39s/it]",
      "\r 21%|██        | 20/95 [00:50<02:57,  2.37s/it]",
      "\r 22%|██▏       | 21/95 [00:53<02:59,  2.43s/it]",
      "\r 23%|██▎       | 22/95 [00:56<03:12,  2.64s/it]",
      "\r 24%|██▍       | 23/95 [00:58<02:58,  2.49s/it]",
      "\r 25%|██▌       | 24/95 [01:01<03:09,  2.67s/it]",
      "\r 26%|██▋       | 25/95 [01:04<03:06,  2.66s/it]",
      "\r 27%|██▋       | 26/95 [01:06<03:00,  2.61s/it]",
      "\r 28%|██▊       | 27/95 [01:09<03:03,  2.69s/it]",
      "\r 29%|██▉       | 28/95 [01:13<03:17,  2.94s/it]",
      "\r 31%|███       | 29/95 [01:16<03:16,  2.97s/it]",
      "\r 32%|███▏      | 30/95 [01:18<03:07,  2.88s/it]",
      "\r 33%|███▎      | 31/95 [01:21<03:00,  2.82s/it]",
      "\r 34%|███▎      | 32/95 [01:23<02:49,  2.68s/it]"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_data = create_train_data()\n",
    "test_data = process_test_data()\n",
    "# if train/test data already exists\n",
    "#train_data = np.load('train_data.npy', allow_pickle=True)\n",
    "#test_data = np.load('test_data.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of Convoluted Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def create_cnn_model():\n",
    "    # tf.reset_default_graph()\n",
    "    model = Sequential()\n",
    "    input_shape = (IMG_SIZE, IMG_SIZE, 1)\n",
    "    \n",
    "    # INPUT LAYER\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "    # HIDDEN LAYER 1\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # HIDDEN LAYER 2\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # HIDDEN LAYER 3\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "    \n",
    "    # HIDDEN LAYER 4\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    # model.add(Dropout(0.25))\n",
    "\n",
    "    # Fully Connected\n",
    "    model.add(Flatten()) # converts the 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(256))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25)) # reduces overfitting\n",
    "\n",
    "    # OUTPUT LAYER\n",
    "    model.add(Dense(NUM_CLASSES))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING THE NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cross Validation Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "ratio = int(round(len(train_data), -1) * 0.2)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train = train_data[:-ratio] # sample train data\n",
    "test = train_data[-ratio:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_X = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # train features (images)\n",
    "train_Y = np.array([i[1] for i in train]) # train labels\n",
    "\n",
    "test_X = np.array([i[0] for i in test]).reshape(-1, IMG_SIZE, IMG_SIZE, 1) # test features (images)\n",
    "test_Y = np.array([i[1] for i in test]) # test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature Scaling (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Have to divide by 255 \n",
    "train_X = train_X/255.0\n",
    "test_X = test_X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"train data: {train_X.shape}\")\n",
    "print(f\"train labels: {train_Y.shape}\")\n",
    "print(f\"test data: {test_X.shape}\")\n",
    "print(f\"test labels: {test_Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency distribution of classes being used in \"test data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "enc = []\n",
    "for img in test:\n",
    "    enc.append(img[1])\n",
    "    \n",
    "enc = np.array(enc)\n",
    "test_labels = mlb.inverse_transform(enc)\n",
    "c = Counter(test_labels)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MODEL = create_cnn_model()\n",
    "MODEL.summary()\n",
    "history = MODEL.fit(train_X, train_Y, batch_size=32, epochs=50, validation_data=(test_X, test_Y), verbose=2, callbacks=[TENSORBOARD])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "MODEL.save(f'{MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"date = datetime.date(2019, 11, 6).strftime('%d-%b-%Y')\n",
    "model_path = f'models/{date}/'\n",
    "MODEL = tf.keras.models.load_model(f'{model_path}')\"\"\"\n",
    "MODEL =  tf.keras.models.load_model(f'{MODEL_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert model to TensorFlow Lite format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(MODEL)\n",
    "tflite_model = converter.convert()\n",
    "open(\"converted_model.tflite\", \"wb\").write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Validate the Converted TFLite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Load TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\") \n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors\n",
    "input_details = interpreter.get_input_details() \n",
    "output_details = interpreter.get_output_details()\n",
    "print(input_details)\n",
    "\n",
    "# Test model on random input data\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(test_X[1].reshape(1,100,100,1), dtype=np.float32) \n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "interpreter.invoke()\n",
    "\n",
    "output_data = interpreter.get_tensor(output_details[0]['index']) \n",
    "print(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Labels Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%run generate_labels_text_file.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "CLASS_INDEX = dict(zip([np.argmax(x) for x in encoded_labels], LABELS.flatten()))\n",
    "# CLASS_INDEX = dict(sorted(CLASS_INDEX.items()))\n",
    "LABELS = LABELS.flatten()\n",
    "IMAGE_IDs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Plot of Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_data = np.load('test_data.npy', allow_pickle=True)\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "results = {cls: [] for cls in LABELS}\n",
    "\n",
    "# iterate over each image in test_sample\n",
    "# get the model's class prediction of the image\n",
    "for num, data in enumerate(test_data):\n",
    "    data[0] = data[0] / 255.0\n",
    "    img_data = data[0]\n",
    "    img_num = data[1]\n",
    "    y = fig.add_subplot(6, 6, num + 1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "    model_out = MODEL.predict([data]).flatten()\n",
    "    index = np.argmax(model_out)\n",
    "    # generate output dictionary\n",
    "    results = {LABELS[i]: results.get(LABELS[i]) + [model_out[i]] for i in range(NUM_CLASSES)}\n",
    "    IMAGE_IDs.append(img_num)\n",
    "    \n",
    "    # cross-reference the predicted class-index to its class-label (for each test image)\n",
    "    class_label = CLASS_INDEX.get(index, 'Invalid class!')\n",
    "    print(f\"Image ID: {img_num}\\t | Prediction: {class_label}\")\n",
    "\n",
    "    y.imshow(orig, cmap='gray')\n",
    "    plt.title(f'{img_num}: {class_label}')\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "# plt.savefig('Class Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "IMAGES_NAMES = [img.split('.')[0] for img in next(os.walk(ALIGNED_TEST_DIR))[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "### Tabulated Prediction Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creates a HeatMap using the seaborn library\n",
    "cm = sns.light_palette(\"red\", as_cmap=True)\n",
    "df = pd.DataFrame.from_dict(results, orient='index', columns=IMAGE_IDs)\n",
    "df.style.\\\n",
    "    format(\"{:.2%}\").\\\n",
    "    set_caption('Confidence Values')\\\n",
    "    .background_gradient(cmap=cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top 5 results for Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Re-structures the results dictionary so that each class_label points to another dictionary {k, v}\n",
    "where k = the Image_Id number and v = the confidence value\n",
    "\"\"\"\n",
    "\n",
    "def gen_results(results):\n",
    "    my_dict = {}\n",
    "    for cls in LABELS:\n",
    "        probs = iter(results[cls])\n",
    "        my_dict.update({cls: {}})\n",
    "        for k in IMAGE_IDs:\n",
    "            my_dict[cls][int(k)] = next(probs)\n",
    "\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top5(results, ID=1):\n",
    "    results = gen_results(results)\n",
    "    probs = np.array([(results[k][ID]) for k in results])\n",
    "    # print(f'Reverse: {(-probs).argsort()} - {sorted(probs, reverse=True)}')\n",
    "    indices = (-probs).argsort()[:5] # sorts probabilities (largest - smallest) + returns their corresponding array indices\n",
    "    top_5 = [CLASS_INDEX.get(i) for i in indices]\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Image_ID = 3\n",
    "TOP_5 = get_top5(results, Image_ID)\n",
    "TOP_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_overall_accuracy(results):\n",
    "    i = 0\n",
    "    num_correct = 0\n",
    "    total = len(test_data) # total number of images\n",
    "    keys = results.keys()\n",
    "    class_labels = []\n",
    "    \n",
    "    for ID in IMAGE_IDs: # loop through each image ID\n",
    "        predictions = []\n",
    "        for key in list(keys): # for each model in the results dictionary\n",
    "            prob = results[key].get(ID)\n",
    "            predictions.append(prob)\n",
    "        max_index = np.argmax(predictions) # max index\n",
    "        label = CLASS_INDEX.get(max_index, 'Invalid class!')\n",
    "        class_labels.append(label)\n",
    "    \n",
    "    for img in os.listdir(ALIGNED_TEST_DIR):\n",
    "        img = img.split('.')[0].strip() # gets the class name of the image file\n",
    "        if img == class_labels[i]:\n",
    "            num_correct += 1\n",
    "        # print(f\"Image name: {img} - predicted label: {class_labels[i]}\")\n",
    "        i += 1 \n",
    "        \n",
    "        \n",
    "    accuracy = round((num_correct / total) * 100, 2)\n",
    "    return f'{accuracy}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "get_overall_accuracy(gen_results(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "Python 3.6 (Tensorflow 2.0)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}