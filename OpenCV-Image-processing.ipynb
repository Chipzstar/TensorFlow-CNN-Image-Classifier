{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%sh\n",
    "# pip install -q pip --upgrade\n",
    "# pip install -q --upgrade opencv-python\n",
    "#pip install --user --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import boto3\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'public/Sofy Soul.png'\n",
    "image_object = S3.get_object(Bucket='pornilarity-bucket170933-production', Key=filename)\n",
    "file_content = image_object[\"Body\"].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([137,  80,  78, ...,  66,  96, 130], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array = np.fromstring(file_content, np.uint8)\n",
    "np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = cv2.imdecode(np_array, cv2.IMREAD_COLOR)\n",
    "\n",
    "gray = cv2.cvtColor(image_tensor, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.resize(gray, (100, 100))\n",
    "image = np.array(image).reshape(-1, 100, 100, 1) # reshapes the image into accepted dimensions (4D tensor)\n",
    "image = tf.cast(image, tf.float32)  # change data type of image to float32\n",
    "image = image / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(1, 100, 100, 1), dtype=float32, numpy=\n",
       "array([[[[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.93333334],\n",
       "         [0.93333334],\n",
       "         [0.9372549 ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.9529412 ],\n",
       "         [0.95686275],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.96862745],\n",
       "         [0.96862745],\n",
       "         [0.96862745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.87058824],\n",
       "         [0.6156863 ],\n",
       "         [0.56078434],\n",
       "         ...,\n",
       "         [0.8235294 ],\n",
       "         [0.7607843 ],\n",
       "         [0.69411767]],\n",
       "\n",
       "        [[0.827451  ],\n",
       "         [0.5921569 ],\n",
       "         [0.5568628 ],\n",
       "         ...,\n",
       "         [0.61960787],\n",
       "         [0.62352943],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        [[0.8039216 ],\n",
       "         [0.5882353 ],\n",
       "         [0.5529412 ],\n",
       "         ...,\n",
       "         [0.7411765 ],\n",
       "         [0.7137255 ],\n",
       "         [0.67058825]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.93333334],\n",
       "         [0.93333334],\n",
       "         [0.9372549 ]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.9529412 ],\n",
       "         [0.95686275],\n",
       "         [0.95686275]],\n",
       "\n",
       "        [[1.        ],\n",
       "         [1.        ],\n",
       "         [1.        ],\n",
       "         ...,\n",
       "         [0.96862745],\n",
       "         [0.96862745],\n",
       "         [0.96862745]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.87058824],\n",
       "         [0.6156863 ],\n",
       "         [0.56078434],\n",
       "         ...,\n",
       "         [0.8235294 ],\n",
       "         [0.7607843 ],\n",
       "         [0.69411767]],\n",
       "\n",
       "        [[0.827451  ],\n",
       "         [0.5921569 ],\n",
       "         [0.5568628 ],\n",
       "         ...,\n",
       "         [0.61960787],\n",
       "         [0.62352943],\n",
       "         [0.6313726 ]],\n",
       "\n",
       "        [[0.8039216 ],\n",
       "         [0.5882353 ],\n",
       "         [0.5529412 ],\n",
       "         ...,\n",
       "         [0.7411765 ],\n",
       "         [0.7137255 ],\n",
       "         [0.67058825]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = cv2.resize(gray, (100, 100))\n",
    "image = np.array(image).reshape(-1, 100, 100, 1) # reshapes the image into accepted dimensions (4D tensor)\n",
    "image = image.astype('float32') # change data type of image to float32\n",
    "image = image / 255.0\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
