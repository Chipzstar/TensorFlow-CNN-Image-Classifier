{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%sh\n",
    "pip install -q pip --upgrade\n",
    "pip install -q sagemaker --upgrade --user\n",
    "pip install -q --upgrade opencv-python\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::780410349667:role/service-role/AmazonSageMaker-ExecutionRole-20191202T133391'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, time\n",
    "import datetime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "DEFAULT_ARN = 'arn:aws:iam::780410349667:role/service-role/AmazonSageMaker-ExecutionRole-20191202T133391'\n",
    "ROLE = get_execution_role()\n",
    "ROLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the SageMaker Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.49.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker as sage\n",
    "print(sage.__version__)\n",
    "session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Docker Image Location from ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'780410349667.dkr.ecr.eu-west-2.amazonaws.com/sagemaker-tf-2-serving:latest'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Docker Image Name\n",
    "image = 'sagemaker-tf-2-serving'\n",
    "\n",
    "# Get the account ID\n",
    "account = session.boto_session.client('sts').get_caller_identity()['Account']\n",
    "\n",
    "# Get the region\n",
    "region = session.boto_session.region_name\n",
    "\n",
    "# Get the custom Image\n",
    "ECR_IMAGE = f'{account}.dkr.ecr.{region}.amazonaws.com/{image}:latest'\n",
    "ECR_IMAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Model.tar.gz and Upload Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import tarfile\\nwith tarfile.open('model.tar.gz', mode='w:gz') as archive:\\n    archive.add('export', recursive=True)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tarfile\n",
    "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('export', recursive=True)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_DATA = session.upload_data(path='model.tar.gz', key_prefix='model')\n",
    "MODEL_DATA = 's3://' + session.default_bucket() + '/model/model.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-west-2-780410349667/model/model.tar.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create TensorFlow Serving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "MODEL = Model(model_data=MODEL_DATA, \n",
    "              role=ROLE,\n",
    "              image=ECR_IMAGE,\n",
    "              framework_version='2.0.0',\n",
    "              sagemaker_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Tensorflow Serving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-tf-2-serving-2019-12-28-14-11-13-544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------!Model Deployed at: 2019-18-28:14-18-52\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "ENDPOINT_NAME = 'pornilarity-v1-endpoint'\n",
    "\n",
    "PREDICTOR = MODEL.deploy(initial_instance_count=1, \n",
    "                         instance_type='ml.c5.xlarge',\n",
    "                         endpoint_name=ENDPOINT_NAME)\n",
    "\n",
    "print(f\"\\nModel Deployed at: {time.strftime('%Y-%M-%d:%H-%M-%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Version: 1.16.4\n",
      "OpenCV Version: 4.1.2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "print(f\"Numpy Version: {np.__version__}\")\n",
    "print(f\"OpenCV Version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploads/Nicole Aniston.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 100, 100, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "image_file = \"uploads/Nicole Aniston.png\"\n",
    "\n",
    "image = cv2.imread(image_file, cv2.IMREAD_GRAYSCALE) # grayscale the image\n",
    "image = cv2.resize(image, (100, 100)) # resize, as our model is expecting images in 32x32.\n",
    "image = np.array(image).reshape(-1, 100, 100, 1) # reshapes the image into accepted dimensions (4D tensor)\n",
    "image = image / 255.0 # Normalisation of RGB pixel values\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTOR.content_type = 'application/json'\n",
    "\n",
    "# For more information on the predictor class.\n",
    "# https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/predictor.py\n",
    "# print(PREDICTOR.predict(image))\n",
    "# print(f\"CloudWatch Log Time: {time.strftime('%Y-%M-%d:%H-%M-%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Client Request using boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format payload into correct json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, codecs, boto3, io\n",
    "\n",
    "JSON_FILE = \"payload.json\"\n",
    "CLIENT = boto3.client('runtime.sagemaker')\n",
    "\n",
    "image_tensor = np.asarray(image).tolist()\n",
    "payload = {\"instances\": image_tensor}\n",
    "\n",
    "# json.dump(payload, codecs.open(JSON_FILE, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Json File containing payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Parameters\n",
    "\n",
    "CUSTOM_ATTRIBUTES = \"c000b4f9-df62-4c85-a0bf-7c525f9104a4\"  # An example of a trace ID.                                 \n",
    "CONTENT_TYPE = \"application/json\"                           # The MIME type of the input data in the request body.\n",
    "ACCEPT = \"application/json\"                                 # The desired MIME type of the inference in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = CLIENT.invoke_endpoint(CustomAttributes=CUSTOM_ATTRIBUTES,\n",
    "                                  EndpointName=ENDPOINT_NAME,\n",
    "                                  ContentType=CONTENT_TYPE,\n",
    "                                  Accept=ACCEPT,\n",
    "                                  Body=json.dumps(payload))\n",
    "\n",
    "response_body = response['Body'].read().decode(\"utf-8\") # decodes byte stream into string format\n",
    "response_body = \" \".join(response_body.split()) # gets rid of all the duplicate whitespaces and newline characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expression to format into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regex = re.compile(\"(?![e])[a-z\\\"\\}\\{:\\s\\[\\]]*\")\n",
    "\n",
    "PREDICTIONS = regex.sub(\"\", response_body).split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTIONS = np.array(PREDICTIONS)\n",
    "PREDICTIONS = PREDICTIONS.astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Top5 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels.txt', 'r') as file:\n",
    "    LABELS = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top5(predictions, labels):\n",
    "    top_5 = []\n",
    "    count = 0\n",
    "    while count < 5:\n",
    "        max_index = np.argmax(predictions)\n",
    "        class_label = labels[max_index]\n",
    "        top_5.append(class_label)\n",
    "        predictions = np.delete(predictions, max_index)\n",
    "        count+=1\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('uploads/Nicole Aniston.png',\n",
       " ['Nicole Aniston', 'Julia Ann', 'Luna Star', 'Sammie Rhodes', 'Aiden Starr'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file, get_top5(PREDICTIONS, LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT_NAME = 'pornilarity-v1-endpoint'\n",
    "session.delete_endpoint(endpoint_name=ENDPOINT_NAME)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
