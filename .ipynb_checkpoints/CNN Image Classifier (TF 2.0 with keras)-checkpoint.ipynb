{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install --upgrade setuptools\n",
    "#!pip install --user --upgrade opencv-python\n",
    "#!pip install --user --upgrade tqdm\n",
    "#!pip install --user --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import boto3, re\n",
    "from collections import Counter\n",
    "from random import shuffle, randint, seed\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version: 3.4.2\n",
      "Tensorflow version: 1.14.0\n",
      "Pillow version: 5.2.0\n"
     ]
    }
   ],
   "source": [
    "print(f'OpenCV version: {cv2.__version__}')\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Pillow version: {PIL.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATE = datetime.date(2019, 11, 21).strftime('%d-%b-%Y')\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "PATH = 'uploads/'\n",
    "MODEL_NAME = 'pornilarity_model'\n",
    "MODEL_PATH = f'export/Servo/{MODEL_NAME}/'\n",
    "IMG_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read in Labels Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('labels.txt', 'r') as file:\n",
    "    LABELS = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Bucket Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Acl',\n",
       " 'Cors',\n",
       " 'Lifecycle',\n",
       " 'LifecycleConfiguration',\n",
       " 'Logging',\n",
       " 'Notification',\n",
       " 'Object',\n",
       " 'Policy',\n",
       " 'RequestPayment',\n",
       " 'Tagging',\n",
       " 'Versioning',\n",
       " 'Website']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S3 = boto3.resource('s3')\n",
    "BUCKET = S3.Bucket('pornilarity-bucket170933-production')\n",
    "BUCKET.get_available_subresources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all images from S3 Bucket into local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for key in BUCKET.objects.all():\\n    name = key.key.split('/')[1]\\n    # print(key.key)\\n    BUCKET.download_file(key.key, f'uploads/{name}')\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for key in BUCKET.objects.all():\n",
    "    name = key.key.split('/')[1]\n",
    "    # print(key.key)\n",
    "    BUCKET.download_file(key.key, f'uploads/{name}')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    test_images = []\n",
    "    for img in tqdm(os.listdir(PATH)):\n",
    "        img_name = str(img).strip() \n",
    "        if img_name == '.ipynb_checkpoints':\n",
    "            print(f'Image filtered: {img_name}')\n",
    "            continue\n",
    "        IMAGE_NAMES.append(img_name)\n",
    "        full_path = os.path.join(PATH, img)  # full path of the image\n",
    "        # print(full_path)\n",
    "        try:\n",
    "            img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = tf.cast(img, tf.float32)  # change data type of image to float32\n",
    "            test_images.append(img)\n",
    "        except Exception as e:\n",
    "            print(full_path)\n",
    "            print(str(e))\n",
    "            \n",
    "    return np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 32/45 [00:01<00:00, 23.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image filtered: .ipynb_checkpoints\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:01<00:00, 23.37it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 44 into shape (100,100,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-9fb2c88bf4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mIMAGE_NAMES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTEST_IMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mTEST_IMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mTEST_IMAGES\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 44 into shape (100,100,1)"
     ]
    }
   ],
   "source": [
    "IMAGE_NAMES = []\n",
    "TEST_IMAGES = process_images()\n",
    "TEST_IMAGES = np.array([i for i in TEST_IMAGES]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 98, 98, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 96, 96, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 46, 46, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 23, 23, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 21, 21, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 10, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 95)                24415     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 95)                0         \n",
      "=================================================================\n",
      "Total params: 1,472,255\n",
      "Trainable params: 1,471,295\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MODEL = tf.keras.models.load_model(f'{MODEL_PATH}')\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_INDEX = dict(zip(list(range(len(LABELS))), LABELS))\n",
    "IMAGE_IDs = iter(range(len(TEST_IMAGES)))\n",
    "\n",
    "def get_predictions(test_images, image_ids):\n",
    "    results = {cls: [] for cls in LABELS}\n",
    "    predicted_labels = []\n",
    "    INDEX = 0\n",
    "    print(\"%-10s %-25s %-20s\" %(\"Image ID\", \"Image Name\", \"Prediction\"))\n",
    "    print(\"***********************************************************\")\n",
    "    for img in test_images:\n",
    "        img = img / 255.0\n",
    "        img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        pred = MODEL.predict(img).flatten()\n",
    "        index = np.argmax(pred)\n",
    "        label = LABELS[index]\n",
    "        results = {LABELS[i]: results.get(LABELS[i]) + [pred[i]] for i in range(len(LABELS))}\n",
    "        print(\"%-10d %-25s %-20s\" %(next(image_ids), IMAGE_NAMES[INDEX], label))\n",
    "        predicted_labels.append(label)\n",
    "        INDEX += 1\n",
    "        \n",
    "    return np.array(predicted_labels), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ID   Image Name                Prediction          \n",
      "***********************************************************\n",
      "0          Evelina Darling.png       Evelina Darling     \n",
      "1          Catarina Petrov.png       Catarina Petrov     \n",
      "2          Samantha Ryan.png         Samantha Ryan       \n",
      "3          Jessica Bangkok.png       Jessica Bangkok     \n",
      "4          Marcelin Abadir.png       Marcelin Abadir     \n",
      "5          Nicole Aniston.png        Nicole Aniston      \n",
      "6          Zaya Cassidy.png          Audrey Bitoni       \n",
      "7          Jenna Sativa.png          Amirah Adara        \n",
      "8          Lisa Ann.png              Marcelin Abadir     \n",
      "9          Emily Willis.png          Emily Willis        \n",
      "10         Dana DeArmond.png         Dana DeArmond       \n",
      "11         Lana Rhoades.png          Lana Rhoades        \n",
      "12         Prinzzess.png             Samantha Ryan       \n",
      "13         Riley Reid.png            Xev Bellringer      \n",
      "14         Sarah Banks.png           Sarah Banks         \n",
      "15         Cherie De Ville.png       Cherie De Ville     \n",
      "16         Bridgette B.png           Bridgette B         \n",
      "17         Deauxma.png               Karlie Montana      \n",
      "18         Tara Morgan.png           Sunny Leone         \n",
      "19         Madison Ivy.png           Madison Ivy         \n",
      "20         Allie Haze.png            Allie Haze          \n",
      "21         Veronica Rodriguez.png    Veronica Rodriguez  \n",
      "22         Mellanie Monroe.png       Brenda James        \n",
      "23         Aiden Starr.png           Aiden Starr         \n",
      "24         Julia Ann.png             Julia Ann           \n",
      "25         Gianna Dior.png           Gianna Dior         \n",
      "26         Valentina Nappi.png       Valentina Nappi     \n",
      "27         Blake Bartelli.png        Blake Bartelli      \n",
      "28         Misty Stone.png           Misty Stone         \n",
      "29         Jessa Rhodes.png          Sunny Leone         \n",
      "30         Isabelle Deltore.png      Isabelle Deltore    \n",
      "31         Kristen Scott.png         Kristen Scott       \n",
      "32         Zoey Holloway.png         Zoey Holloway       \n",
      "33         Anita Dark.png            Riley Steele        \n",
      "34         Sofy Soul.png             Tiffany Tatum       \n",
      "35         Krystal Boyd.png          Krystal Boyd        \n",
      "36         Tanya Tate.png            Tanya Tate          \n",
      "37         Osa Lovely.png            Madison Ivy         \n",
      "38         Ariella Ferrera.png       Audrey Bitoni       \n",
      "39         Romi Rain.png             Romi Rain           \n",
      "40         Andriana Chechik.png      Andriana Chechik    \n",
      "41         Mia Khalifa.png           Mia Khalifa         \n",
      "42         Peta Jensen.png           Peta Jensen         \n",
      "43         Stella Cox.png            Stella Cox          \n"
     ]
    }
   ],
   "source": [
    "PREDICTED_LABELS, RESULTS = get_predictions(TEST_IMAGES, IMAGE_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top 5 results for Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Re-structures the results dictionary so that each class_label points to another dictionary {k, v}\n",
    "where k = the Image_Id number and v = the confidence value\n",
    "\"\"\"\n",
    "IMAGE_IDs = list(range(len(TEST_IMAGES)))\n",
    "def gen_results(results):\n",
    "    my_dict = {}\n",
    "    for cls in LABELS:\n",
    "        probs = iter(results[cls])\n",
    "        my_dict.update({cls: {}})\n",
    "        for k in IMAGE_IDs:\n",
    "            my_dict[cls][int(k)] = next(probs)\n",
    "\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top5(results, ID=1):\n",
    "    results = gen_results(results)\n",
    "    probs = np.array([(results[k][ID]) for k in results])\n",
    "    indices = (-probs).argsort()[:5] # sorts probabilities (largest - smallest) + returns their corresponding array indices\n",
    "    top_5 = [CLASS_INDEX.get(i) for i in indices]\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Image_ID = 6\n",
    "TOP_5 = get_top5(RESULTS, Image_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save array of Top5 results as a textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Top5.txt\", TOP_5, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results back to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = f'top5-test_img-{int(time.time())}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET.upload_file('Top5.txt', f'results/{FILE}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
