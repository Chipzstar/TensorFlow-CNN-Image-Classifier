{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"!pip install --upgrade pip\n",
    "!pip install --user --upgrade opencv-python\n",
    "!pip install --user --upgrade tqdm\n",
    "!pip install --user --upgrade tensorflow\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import PIL\n",
    "import boto3, re\n",
    "from collections import Counter\n",
    "from random import shuffle, randint, seed\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(f'OpenCV version: {cv2.__version__}')\n",
    "print(f'Tensorflow version: {tf.__version__}')\n",
    "print(f'Pillow version: {PIL.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "DATE = datetime.date(2019, 11, 21).strftime('%d-%b-%Y')\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "PATH = 'uploads/'\n",
    "MODEL_PATH = f'models/{DATE}/'\n",
    "MODEL_NAME = 'ImageClassifier-keras-5-Conv-Layer-{}.model'.format(int(time.time()))\n",
    "DATE, IMG_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read in Labels Text File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('labels.txt', 'r') as file:\n",
    "    LABELS = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Bucket Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3 = boto3.resource('s3')\n",
    "BUCKET = S3.Bucket('pornilarity-bucket170933-production')\n",
    "BUCKET.get_available_subresources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download all images from S3 Bucket into local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in BUCKET.objects.all():\n",
    "    name = key.key.split('/')[1]\n",
    "    # print(key.key)\n",
    "    BUCKET.download_file(key.key, f'uploads/{name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images():\n",
    "    test_images = []\n",
    "    for img in tqdm(os.listdir(PATH)):\n",
    "        img_name = str(img).strip() \n",
    "        if img_name == '.ipynb_checkpoints':\n",
    "            print(img_name)\n",
    "            continue\n",
    "        IMAGE_NAMES.append(img_name)\n",
    "        full_path = os.path.join(PATH, img)  # full path of the image\n",
    "        # print(full_path)\n",
    "        try:\n",
    "            img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "            img = tf.cast(img, tf.float32)  # change data type of image to float32\n",
    "            test_images.append(img)\n",
    "        except Exception as e:\n",
    "            print(full_path)\n",
    "            print(str(e))\n",
    "            \n",
    "    return np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAMES = []\n",
    "TEST_IMAGES = process_images()\n",
    "TEST_IMAGES = np.array([i for i in TEST_IMAGES]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "MODEL = tf.keras.models.load_model(f'{MODEL_PATH}')\n",
    "MODEL.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_INDEX = dict(zip(list(range(len(LABELS))), LABELS))\n",
    "IMAGE_IDs = iter(range(len(TEST_IMAGES)))\n",
    "\n",
    "def get_predictions(test_images, image_ids):\n",
    "    results = {cls: [] for cls in LABELS}\n",
    "    predicted_labels = []\n",
    "    INDEX = 0\n",
    "    print(\"%-10s %-25s %-20s\" %(\"Image ID\", \"Image Name\", \"Prediction\"))\n",
    "    print(\"***********************************************************\")\n",
    "    for img in test_images:\n",
    "        img = img / 255.0\n",
    "        img = img.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "        pred = MODEL.predict(img).flatten()\n",
    "        index = np.argmax(pred)\n",
    "        label = LABELS[index]\n",
    "        results = {LABELS[i]: results.get(LABELS[i]) + [pred[i]] for i in range(len(LABELS))}\n",
    "        # print(f\"Image ID: {next(IMAGE_IDs)}\\t| Image Name: {IMAGE_NAMES[INDEX]} \\t| Prediction: {label}\")\n",
    "        print(\"%-10d %-25s %-20s\" %(next(image_ids), IMAGE_NAMES[INDEX], label))\n",
    "        predicted_labels.append(label)\n",
    "        INDEX += 1\n",
    "        \n",
    "    return np.array(predicted_labels), results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTED_LABELS, RESULTS = get_predictions(TEST_IMAGES, IMAGE_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top 5 results for Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Re-structures the results dictionary so that each class_label points to another dictionary {k, v}\n",
    "where k = the Image_Id number and v = the confidence value\n",
    "\"\"\"\n",
    "IMAGE_IDs = list(range(len(TEST_IMAGES)))\n",
    "def gen_results(results):\n",
    "    my_dict = {}\n",
    "    for cls in LABELS:\n",
    "        probs = iter(results[cls])\n",
    "        my_dict.update({cls: {}})\n",
    "        for k in IMAGE_IDs:\n",
    "            my_dict[cls][int(k)] = next(probs)\n",
    "\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_top5(results, ID=1):\n",
    "    results = gen_results(results)\n",
    "    probs = np.array([(results[k][ID]) for k in results])\n",
    "    indices = (-probs).argsort()[:5] # sorts probabilities (largest - smallest) + returns their corresponding array indices\n",
    "    top_5 = [CLASS_INDEX.get(i) for i in indices]\n",
    "    return top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Image_ID = 6\n",
    "TOP_5 = get_top5(RESULTS, Image_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save array of Top5 results as a textfile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"Top5.txt\", TOP_5, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload results back to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = f'top5-test_img-{int(time.time())}.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET.upload_file('Top5.txt', f'results/{FILE}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
